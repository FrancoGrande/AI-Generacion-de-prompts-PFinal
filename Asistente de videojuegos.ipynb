{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f5e6bba-f9b0-4d27-a0c2-ceede346e2fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180968b-5de0-4e1d-91e1-bb0607b62ebe",
   "metadata": {},
   "source": [
    "2. Use the API Key from gemini page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaa13f6c-6aee-4ddd-92b7-33dbbf66ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c1fc76-a9ea-4df9-9324-d83bba8bfc0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42ce140-d99c-492e-ad64-9de2719ea75e",
   "metadata": {},
   "source": [
    "Configuramos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ce51fc0-ce3e-4db1-8ab5-4d9447252af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\Desktop\\IA_prompts\\ejemplo.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Make the request\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m conversation \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: context},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m ]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     messages\u001b[39m=\u001b[39;49mconversation,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m message \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/Desktop/IA_prompts/ejemplo.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(message[\u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m], message[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: You didn't provide an API key. You need to provide your API key in an Authorization header using Bearer auth (i.e. Authorization: Bearer YOUR_KEY), or as the password field (with blank username) if you're accessing the API from your browser and are prompted for a username and password. You can obtain an API key from https://platform.openai.com/account/api-keys."
     ]
    }
   ],
   "source": [
    "generation_config = {\n",
    "    \"temperature\": 0.28,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro\",\n",
    "  generation_config=generation_config,\n",
    "\n",
    "    system_instruction=\"Sos un asistente virtual en videojuegos, tu tarea es asistir a los jugadores con sus problemas, podes mostrar un tutorial, dar pistas sobre la situacion en la que esta el jugador y como solucionarla sin hacerle spoiler en la trama\",\n",
    ")\n",
    "\n",
    "chat_session = model.start_chat(\n",
    "    history=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "        \"Como me gano la confianza de shadowheart en baldur´s gate 3?\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "        \"¡Entiendo que quieres ganarte el favor del misterioso Corazón Sombrío en Baldur's Gate 3!  Es un objetivo intrigante, y sin duda te espera un camino interesante. \\n\\nPara guiarte sin arruinarte la experiencia, te recomiendo lo siguiente:\\n\\n**Presta atención a las pistas:** Corazón Sombrrío tiene... preferencias particulares. Observa sus reacciones a tus acciones y decisiones durante el juego. ¿Qué tipo de elecciones parecen complacerlo? ¿Qué lo desagrada? \\n\\n**Diálogos reveladores:**  No te saltes los diálogos con Corazón Sombrío.  Las opciones que elijas al hablar con él  revelarán mucho sobre sus deseos y te darán una idea de cómo fortalecer vuestro vínculo. \\n\\n**Recuerda, las acciones hablan más que las palabras:** A veces, la manera de obtener la aprobación de Corazón Sombrío no se encuentra en lo que dices, sino en lo que haces. Piensa en cómo tus acciones en el mundo reflejan lo que has aprendido sobre sus valores. \\n\\nTen en cuenta que el camino para ganarse el favor de Corazón Sombrío puede ser complejo y depende de tus elecciones a lo largo de la historia.  ¡Buena suerte aventurero!  \\n\",\n",
    "        ],\n",
    "    },\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(\"Quiero saber como contentar a karlash en baldurs gate 3, que le gusta\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2ce41-0dc8-46f9-8137-aca58604bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El resumen de dicha converzacion es: En esta conversación se abordaron diversos temas relacionados con la compra y venta de criptomonedas, así como el tipo de cambio al comprar con tarjeta del exterior.\n",
      "\n",
      "Se mencionó que el cambio en los últimos días ha estado alrededor de $985 por cada dólar, pero se aclaró que esto no se aplica a las tarjetas del exterior, ya que el aumento en los impuestos confiscatorios es solo para las tarjetas nacionales\n"
     ]
    }
   ],
   "source": [
    "chat_history =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a0bbc-0af1-4006-aea0-78dc22675505",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = model.start_chat(\n",
    "    history= chat_history\n",
    ")\n",
    "\n",
    "response = chat_session.send_message(\"Quiero saber como contentar a karlash en baldurs gate 3\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b664a",
   "metadata": {},
   "source": [
    "Creamos las funciones donde se inicia la conversación y por otro lado el historial de la conversación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f88714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chat_history():\n",
    "    print(\"\\nHistorial de la conversación:\")\n",
    "\n",
    "    for entry in chat_history:\n",
    "        role = \"Usuario\" if entry['role'] == 'user' else \"Bot\"\n",
    "        print(f\"{role}: {' '.join(entry['parts'])}\")\n",
    "\n",
    "def infinite_chat():\n",
    "    chat_session = model.start_chat(\n",
    "    history= chat_history\n",
    "    )\n",
    "while True:\n",
    "    user_input= input(\"you: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = chat_session.send_message(user_input)\n",
    "    print(\"bot: \", response.text)\n",
    "\n",
    "    chat_history.append({'role': 'user', 'parts': [user_input] })\n",
    "    chat_history.append({'role': 'model', 'parts': [response.text] })\n",
    "\n",
    "    print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a67a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infinite_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_chat_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d069fa",
   "metadata": {},
   "source": [
    "Ahora le pediremos que describa una imagen del mismo juego "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd696f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6a1d7",
   "metadata": {},
   "source": [
    "Siguiente descargamos una imagen para que luego la analice y la describa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o image.jpg \"https://image.api.playstation.com/vulcan/ap/rnd/202302/2321/3098481c9164bb5f33069b37e49fba1a572ea3b89971ee7b.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8ea2e",
   "metadata": {},
   "source": [
    "variable para utilizarla en el codigo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "img = PIL.Image.open('image.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec107f2",
   "metadata": {},
   "source": [
    "Ahora creamos el codigo para que la describa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(['describime a la persona de la imagen', img])\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
